{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Machine Learning Model\n",
    "## Applied to Voting Behavior in Arizona\n",
    "### Keras Neural Network \n",
    "\n",
    "\n",
    "Below I just load a bunch of dependencies. I follow this with a GBQ query to get the data. I then do some data cleaning. Finally, I split the data into train and test sets.    \n",
    "\n",
    "A political engagement indicator was created, scored 1 if the voter participated in the 2020 primary, as well as the 2018 primary and general elections. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/Chris/Dropbox/Keys/az-voter-file-30395362c45b.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Always manage your python environments. I had to create a special one here because of my M1 chip. Don't ask me why, I don't know why tensorflow requires a separate build, but it does. For me it requires\n",
    "\n",
    "**pip install tensorflow-macos==2.4.1**\n",
    "\n",
    "**pip install tensorflow-metal==0.1.1**\n",
    "\n",
    "But first -- and this is important -- create a virtual environment. There are a lot of conflicts that arise, and it's just easiest to keep separate spaces. Something like this:\n",
    "\n",
    "**python3 -m venv \"/Users/Chris/website_fall22/site/tensorflow\"**\n",
    "\n",
    "**source \"/Users/Chris/website_fall22/site/tensorflow/bin/activate\"**\n",
    "\n",
    "Then... pip install upgrade and pip install all the packages, like pandas, numpy, sklearn, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I query the BQ below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 3860252/3860252 [09:16<00:00, 6940.48rows/s]\n"
     ]
    }
   ],
   "source": [
    "### Formulate the SQL query to pull the data from BigQuery\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "    geo_id,\n",
    "    registrant_id,\n",
    "    general_2020,\n",
    "    primary_2020,\n",
    "    general_2018,\n",
    "    primary_2018,\n",
    "    general_2016,\n",
    "    primary_2016,\n",
    "    general_2014,\n",
    "    bachelors_degree,\n",
    "    total_pop,\n",
    "    birth_year,\n",
    "    registration_date,\n",
    "    registration_change,\n",
    "    median_age,\n",
    "    median_income,\n",
    "    white_pop,\n",
    "    black_pop,\n",
    "    asian_pop,\n",
    "    hispanic_pop,\n",
    "    amerindian_pop,\n",
    "    housing_units,\n",
    "    employed_pop,\n",
    "    armed_forces,\n",
    "    pop_in_labor_force,\n",
    "FROM `az-voter-file.registration.clean_data_machine_learning_blocks`\n",
    "\"\"\"\n",
    "\n",
    "df = pandas_gbq.read_gbq(query, project_id=\"az-voter-file\")\n",
    "df.to_pickle('voter_file00_00_02.pkl') ## For later load, not to sync."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty rudimentary, and likely overkill, but we can compare it to far simpler measures as well. I created a variable, called \"engaged, that is 1 if the voter participated in the 2020 primary, as well as the 2018 primary and general elections. I then split the data in half, into a test set and a train set. I then train a model on the train set, and test it on the test set. The model I use is a \"neural network\" with an input layer, 4 hidden layers, and an output layer. I tested this, specifying different parameterizations and hidden layers. It really doesn't matter. I hit about 85% accuracy, which is marginal, but far better than chance for these data. The features I use to train the model are, primary and general election voting prior to 2018, as well as the following characteristics measured at the  characteristics:\n",
    "_________\n",
    "### Voter Level Information\n",
    "______\n",
    "* 'general_2016', \n",
    "* 'bachelors_degree_2',\n",
    "* 'primary_2016', \n",
    "* 'general_2014', \n",
    "* 'registration_change',\n",
    "* 'registration_date',\n",
    "* 'age'\n",
    "_________\n",
    "### Tract level Information\n",
    "_________\n",
    "* 'poverty',\n",
    "* 'age', \n",
    "* 'median_age', \n",
    "* 'median_income',\n",
    "* 'white_pop', \n",
    "* 'black_pop', \n",
    "* 'asian_pop', \n",
    "* 'hispanic_pop', \n",
    "* 'amerindian_pop', \n",
    "* 'gini_index', \n",
    "* 'housing_units', \n",
    "* 'employed_pop' \n",
    "\n",
    "All variables were 0-1 standardized prior to analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "#\"https://caffeinedev.medium.com/how-to-install-tensorflow-on-m1-mac-8e9b91d93706\"\n",
    "\n",
    "df = pd.read_pickle('voter_file00_00_02.pkl')\n",
    "\n",
    "reg_length =  (pd.to_datetime(\"11-04-2020\", format = \"%m-%d-%Y\") - pd.to_datetime(df['registration_date'], \n",
    "                              format = \"%Y-%m-%d\", \n",
    "                              errors = 'coerce'))\n",
    "df[\"registration_length\"] = reg_length.dt.days \n",
    "\n",
    "reg_change=  (pd.to_datetime(\"11-04-2020\", format = \"%m-%d-%Y\") - pd.to_datetime(df['registration_change'], \n",
    "                                format = \"%Y-%m-%d\", errors = 'coerce'))\n",
    "df[\"registration_change\"] = reg_change.dt.days \n",
    "\n",
    "\n",
    "\n",
    "st_dat = df[['general_2020', 'primary_2020', 'general_2018', \n",
    "    'primary_2018', 'general_2016', \"bachelors_degree\",\n",
    "    'primary_2016', 'general_2014',\n",
    "    'registration_length', \n",
    "    'registration_change',\n",
    "    'median_age', 'median_income',\n",
    "    'white_pop', 'black_pop', 'asian_pop', 'hispanic_pop', \n",
    "    'amerindian_pop', 'housing_units', \n",
    "    'employed_pop']]\n",
    " \n",
    "st_dat = st_dat.dropna(how = 'any')\n",
    "scaler = MinMaxScaler()\n",
    "st_dat_array = scaler.fit_transform(st_dat)\n",
    "st_dat = pd.DataFrame(st_dat_array, columns = st_dat.columns)\n",
    "\n",
    "\n",
    "st_dat['engaged'] = np.where((((st_dat[\"primary_2018\"] == 1)  \n",
    "                                     & (st_dat[\"primary_2020\"] == 1) \n",
    "                                     & (st_dat[\"general_2018\"] == 1)\n",
    "                                    )),1,0) \n",
    "train, test = train_test_split(st_dat, test_size=0.2)\n",
    "\n",
    "features_train   =  train[['general_2016',  \"bachelors_degree\", \n",
    "                            'primary_2016', 'general_2014', \n",
    "                            'registration_length', \n",
    "                            'registration_change',\n",
    "                            'median_age', 'median_income',\n",
    "                            'white_pop', 'black_pop', 'asian_pop', 'hispanic_pop', \n",
    "                            'amerindian_pop', 'housing_units', \n",
    "                            'employed_pop']]\n",
    "labels_train     =  pd.DataFrame({\"engaged\":train['engaged'],  \"not_engaged\":1-train['engaged']})\n",
    "\n",
    "\n",
    "features_train_array = np.array(features_train, np.float64)\n",
    "labels_train_array   = np.array(labels_train,   np.float64)\n",
    "\n",
    "\n",
    "features_test   = test[['general_2016',  \"bachelors_degree\", \n",
    "                            'primary_2016', 'general_2014', \n",
    "                            'registration_length', \n",
    "                            'registration_change',\n",
    "                            'median_age', 'median_income',\n",
    "                            'white_pop', 'black_pop', 'asian_pop', 'hispanic_pop', \n",
    "                            'amerindian_pop', 'housing_units', \n",
    "                            'employed_pop']]\n",
    "labels_test     =  pd.DataFrame({\"engaged\":test['engaged'],  \"not_engaged\":1-test['engaged']})\n",
    "\n",
    "\n",
    "features_test_array = np.array(features_test, np.float64)\n",
    "labels_test_array   = np.array(labels_test,   np.float64)\n",
    "\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "model = tf.keras.Sequential()\n",
    "# Define the first layer\n",
    "model.add(keras.layers.Dense(20, activation='softmax', \n",
    "                               input_shape=(features_train.shape[1],)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "# model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "# model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    \n",
    "\n",
    "# Finish the model compilation\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "# #! pip install tensorflow-macos --upgrade \n",
    "# import tensorflow as tf\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.2\n",
      "Num GPUs Available:  1\n",
      "Epoch 1/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3882 - accuracy: 0.8418 - val_loss: 0.3826 - val_accuracy: 0.8422\n",
      "Epoch 2/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3880 - accuracy: 0.8419 - val_loss: 0.3824 - val_accuracy: 0.8421\n",
      "Epoch 3/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3875 - accuracy: 0.8418 - val_loss: 0.3822 - val_accuracy: 0.8421\n",
      "Epoch 4/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3873 - accuracy: 0.8420 - val_loss: 0.3822 - val_accuracy: 0.8422\n",
      "Epoch 5/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3874 - accuracy: 0.8420 - val_loss: 0.3820 - val_accuracy: 0.8423\n",
      "Epoch 6/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3871 - accuracy: 0.8421 - val_loss: 0.3819 - val_accuracy: 0.8424\n",
      "Epoch 7/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3870 - accuracy: 0.8423 - val_loss: 0.3817 - val_accuracy: 0.8424\n",
      "Epoch 8/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3868 - accuracy: 0.8423 - val_loss: 0.3816 - val_accuracy: 0.8424\n",
      "Epoch 9/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3869 - accuracy: 0.8421 - val_loss: 0.3818 - val_accuracy: 0.8425\n",
      "Epoch 10/10\n",
      "1970/1970 [==============================] - 18s 9ms/step - loss: 0.3868 - accuracy: 0.8421 - val_loss: 0.3816 - val_accuracy: 0.8424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x57750b550>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "model.fit(features_train_array, \n",
    "          labels_train_array, epochs=10, batch_size=1000, \n",
    "          validation_split=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, where I constructed the training data, I also set aside 20 percent of the sample. **The model was not trained on this model. These are fresh data, randomly drawn, so that we can compare the outcome to the predicted outcome.** Overall, I reach about 85% acccuracy, which is not great, but far better than chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test   =   test[['general_2016',  \"bachelors_degree\",\n",
    "                            'primary_2016', 'general_2014',   'registration_length', \n",
    "                            'registration_change',\n",
    "                            'median_age', 'median_income',\n",
    "                            'white_pop', 'black_pop', 'asian_pop', 'hispanic_pop', \n",
    "                            'amerindian_pop', 'housing_units', \n",
    "                            'employed_pop']]\n",
    "labels_test     =  pd.DataFrame({\"engaged\":test['engaged'],  \"not_engaged\":1-test['engaged']})\n",
    "features_test_array = np.array(features_test, np.float64)\n",
    "labels_test_array   = np.array(labels_test,   np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   92/19234 [..............................] - ETA: 31s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 11:12:28.511711: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19234/19234 [==============================] - 30s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "outcome = model.predict(features_test_array) > 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've tinkered with the model quite a bit. I can't seem to improve it. It's not a remarkable degree of accuracy, but there's really not all that much individual level data, so I'm not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19234/19234 [==============================] - 29s 2ms/step\n",
      "76936/76936 [==============================] - 114s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8436642"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1 = model.predict(features_test_array) > 0.5\n",
    "preds2 = model.predict(features_train_array)\n",
    "\n",
    "# Evaluate the model\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
    "acc = Accuracy()\n",
    "prec = Precision()\n",
    "recall = Recall()\n",
    "acc.update_state(labels_test_array, preds1)\n",
    "\n",
    "acc.result().numpy()\n",
    "# prec.result().numpy()\n",
    "# recall.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardize the data, train with variables below ####\n",
    "full_data = df[['registrant_id', 'general_2020', 'primary_2020', 'general_2018', \n",
    "    'primary_2018', 'general_2016', \"bachelors_degree\",\n",
    "    'primary_2016', 'general_2014',\n",
    "    'registration_length', \n",
    "    'registration_change',\n",
    "    'median_age', 'median_income',\n",
    "    'white_pop', 'black_pop', 'asian_pop', 'hispanic_pop', \n",
    "    'amerindian_pop',  'housing_units', \n",
    "    'employed_pop']]\n",
    "full_data = full_data.dropna(how = 'any')\n",
    "registrant_id = full_data['registrant_id']\n",
    "full_data_array = scaler.fit_transform(full_data)\n",
    "full_data = pd.DataFrame(full_data_array, columns = full_data.columns)\n",
    "full_data['engaged'] = np.where((((full_data[\"primary_2018\"] == 1)  \n",
    "                                     & (full_data[\"primary_2020\"] == 1) \n",
    "                                     & (full_data[\"general_2018\"] == 1)\n",
    "                                    )),1,0) \n",
    "labels_full     =  pd.DataFrame({\"engaged\": full_data['engaged'],  \"not_engaged\": 1-full_data['engaged']})\n",
    "features_full    =  full_data[['general_2016', \"bachelors_degree\",\n",
    "    'primary_2016', 'general_2014', \n",
    "     'registration_length', \n",
    "    'registration_change',\n",
    "    'median_age', 'median_income',\n",
    "    'white_pop', 'black_pop', 'asian_pop', 'hispanic_pop', \n",
    "    'amerindian_pop',  'housing_units', \n",
    "    'employed_pop']]\n",
    "\n",
    "features_full_array = np.array(features_full, np.float64)\n",
    "labels_full_array   = np.array(labels_full,   np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26994/96170 [=======>......................] - ETA: 1:41"
     ]
    }
   ],
   "source": [
    "preds = model.predict(features_full_array)\n",
    "preds = pd.DataFrame(preds)\n",
    "preds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(1, preds.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engaged_pr</th>\n",
       "      <th>not_engaged_pr</th>\n",
       "      <th>point</th>\n",
       "      <th>engaged_true</th>\n",
       "      <th>registrant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643133</td>\n",
       "      <td>0.356867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22484551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.914875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23496232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.224582</td>\n",
       "      <td>0.775418</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22302082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.519468</td>\n",
       "      <td>0.480532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22274355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086591</td>\n",
       "      <td>0.913409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27379527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engaged_pr  not_engaged_pr  point  engaged_true registrant_id\n",
       "0    0.643133        0.356867      1             1      22484551\n",
       "1    0.085125        0.914875      0             0      23496232\n",
       "2    0.224582        0.775418      0             1      22302082\n",
       "3    0.519468        0.480532      1             0      22274355\n",
       "4    0.086591        0.913409      0             0      27379527"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_data = pd.DataFrame( {\"engaged_pr\" : preds.iloc[:,0], \n",
    "                    \"not_engaged_pr\" : preds.iloc[:,1],  \n",
    "                    \"point\" : np.random.binomial(1, preds.iloc[:,0]),\n",
    "                    \"engaged_true\" :  full_data[\"engaged\"],\n",
    "                    \"registrant_id\" : registrant_id.tolist() } )\n",
    "\n",
    "upload_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3292.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas_gbq\n",
    "bqclient = bigquery.Client()\n",
    "project_id = \"az-voter-file\"\n",
    "pandas_gbq.to_gbq(upload_data, \"az-voter-file.registration.nn04\", project_id=project_id, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv( \"not_uploaded.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tensorflow': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "837da91509cbd5b9bb69bb922d3658836683c892f657df3b153a009ccfc4f585"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
